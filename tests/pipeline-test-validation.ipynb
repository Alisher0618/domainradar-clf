{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6da3c57-6b29-4cbb-acb8-511c54f94612",
   "metadata": {},
   "source": [
    "# Test of the clasification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d7a8113-ad05-423b-9ec2-9f9c5d370cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory has already been changed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to change to the parent directory\n",
    "def change_to_parent_directory():\n",
    "    # Check if the directory has already been changed\n",
    "    if not os.environ.get('DIR_CHANGED'):\n",
    "        try:\n",
    "            current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        except NameError:\n",
    "            current_dir = os.getcwd()\n",
    "        parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "        os.chdir(parent_dir)\n",
    "        os.environ['DIR_CHANGED'] = '1'\n",
    "        print(f\"Current working directory changed to: {os.getcwd()}\")\n",
    "    else:\n",
    "        print(\"Directory has already been changed.\")\n",
    "\n",
    "# Call the function to change the working directory\n",
    "change_to_parent_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153698e5-fbe9-4203-b6e2-468c9367dd26",
   "metadata": {},
   "source": [
    "## Optional: Create testing dataset\n",
    "Note: If you want do to this, set create_test_parquet to **True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3e2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d2736c9-87aa-4055-9ff4-f9e05228ddaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['domain_name', 'dns_has_dnskey', 'dns_A_count', 'dns_AAAA_count',\n",
      "       'dns_MX_count', 'dns_NS_count', 'dns_TXT_count', 'dns_SOA_count',\n",
      "       'dns_CNAME_count', 'dns_zone_level',\n",
      "       ...\n",
      "       'html_num_of_form_js', 'html_malicious_form', 'html_most_common',\n",
      "       'html_num_of_css_internal', 'html_num_of_css_external',\n",
      "       'html_num_of_anchors_to_content', 'html_num_of_anchors_to_void',\n",
      "       'html_num_of_blank_spaces', 'html_blocked_keywords_label', 'label'],\n",
      "      dtype='object', length=265)\n"
     ]
    }
   ],
   "source": [
    "create_test_parquet = True\n",
    "\n",
    "if create_test_parquet:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # List of input Parquet files along with their maximum rows and desired labels\n",
    "    #input_files = [\n",
    "    #    {'file': 'testdata/2405_clftest_benign_filtered.parquet', 'max_rows': 4000, 'label': 'benign'},\n",
    "    #    {'file': 'testdata/2405_clftest_phishing_filtered.parquet', 'max_rows': 480, 'label': 'phishing'},\n",
    "    #    {'file': 'testdata/2405_clftest_malware_filtered.parquet', 'max_rows': 292, 'label': 'malware'},\n",
    "    #    {'file': 'testdata/dga_2310.parquet', 'max_rows': 300, 'label': 'dga'},\n",
    "    #]\n",
    "\n",
    "    input_files = [\n",
    "        {'file': 'testdata/2405_clftest_benign_filtered_HTML.parquet', 'max_rows': 500, 'label': 'benign'},\n",
    "        {'file': 'testdata/2405_clftest_phishing_filtered_HTML.parquet', 'max_rows': 242, 'label': 'phishing'},\n",
    "        {'file': 'testdata/2405_clftest_malware_filtered_HTML.parquet', 'max_rows': 77, 'label': 'malware'},\n",
    "        {'file': 'testdata/dga_2310.parquet', 'max_rows': 300, 'label': 'dga'}\n",
    "    ]\n",
    "\n",
    "    # Number of rows to select in total\n",
    "    #n_rows = 5072\n",
    "    n_rows = 210\n",
    "    \n",
    "    # Read the first file to get the initial columns and create the first dataframe\n",
    "    first_file_info = input_files[0]\n",
    "    combined_df = pd.read_parquet(first_file_info['file'])\n",
    "    \n",
    "    # Limit the number of rows if necessary for the first file\n",
    "    if len(combined_df) > first_file_info['max_rows']:\n",
    "        combined_df = combined_df.sample(n=first_file_info['max_rows'], random_state=1)\n",
    "    \n",
    "    # Overwrite the \"label\" column with the specified label for the first file\n",
    "    combined_df['label'] = first_file_info['label']\n",
    "    \n",
    "    # Get the columns from the first dataframe\n",
    "    all_columns = combined_df.columns.tolist()\n",
    "\n",
    "    # Process the remaining files\n",
    "    for file_info in input_files[1:]:\n",
    "        df = pd.read_parquet(file_info['file'])\n",
    "        \n",
    "        # Limit the number of rows if necessary\n",
    "        if len(df) > file_info['max_rows']:\n",
    "            df = df.sample(n=file_info['max_rows'], random_state=1)\n",
    "        \n",
    "        # Overwrite the \"label\" column with the specified label\n",
    "        df['label'] = file_info['label']\n",
    "        \n",
    "        # Ensure all columns from the first dataframe are present\n",
    "        for col in all_columns:\n",
    "            if col not in df.columns:\n",
    "                df[col] = None\n",
    "        \n",
    "        # Align the dataframe to the columns of the first dataframe\n",
    "        df = df[all_columns]\n",
    "        \n",
    "        # Append the dataframe to the combined dataframe\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    # Handle NaNs\n",
    "    combined_df.fillna(-1, inplace=True)\n",
    "    \n",
    "    # Randomly select n_rows rows from the combined DataFrame\n",
    "    selected_rows = combined_df.sample(n=n_rows, random_state=1)  # random_state for reproducibility\n",
    "\n",
    "    selected_rows = selected_rows.drop(columns=['label_x', 'label_y'], errors='ignore')\n",
    "    \n",
    "    # Save the selected rows to a new Parquet file\n",
    "    selected_rows.to_parquet('testdata/ver_html_test.parquet')\n",
    "    print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c279e87c-6092-45a7-9b0b-436ed3299948",
   "metadata": {},
   "source": [
    "## Run classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e032f178-d788-4bee-909e-d0c7ce26d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parquet file with the dataset for classification\n",
    "test_dataset = 'testdata/ver_html_test.parquet'\n",
    "\n",
    "# Number of domain names to classify with each run of the pipeline (0 = classify all)\n",
    "CHUNK_SIZE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "869c6cdc-3f2d-4f13-85ea-a6d6ae50d359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<classifiers.options.PipelineOptions object at 0x7faa15d8bf10>\n",
      "CNN model created\n",
      "<classifiers.pipeline.Pipeline object at 0x7faa15db5210>\n",
      "                                           domain_name  dns_has_dnskey  \\\n",
      "92                                      www.niwens.com             0.0   \n",
      "148                                     www.borsice.cz             1.0   \n",
      "159                            srockwell.formstack.com             0.0   \n",
      "460                                    yxglhsxtpbbl.so             0.0   \n",
      "453                                         imrebm.com             0.0   \n",
      "..                                                 ...             ...   \n",
      "351                              tajnikidowodowe.click             0.0   \n",
      "346                                 dailyhousetips.com             0.0   \n",
      "38   xn--80aakec5bilkue.xn--33-6kcadhwnl3cfdx.xn--p1ai             0.0   \n",
      "667                                         sbhriz.com             0.0   \n",
      "259                       4210qthn.computer-mod-s.tech             1.0   \n",
      "\n",
      "     dns_A_count  dns_AAAA_count  dns_MX_count  dns_NS_count  dns_TXT_count  \\\n",
      "92             1               0             0             0              0   \n",
      "148            0               0             0             0              0   \n",
      "159            0               0             0             0              0   \n",
      "460            0               0             0             0              0   \n",
      "453            0               0             0             0              0   \n",
      "..           ...             ...           ...           ...            ...   \n",
      "351            2               2             1             2              1   \n",
      "346            2               2             0             2              1   \n",
      "38             1               0             0             0              0   \n",
      "667            0               0             0             0              0   \n",
      "259            2               2             0             0              0   \n",
      "\n",
      "     dns_SOA_count  dns_CNAME_count  dns_zone_level  ...  html_num_of_form_js  \\\n",
      "92               0                0               0  ...                  0.0   \n",
      "148              0                1               0  ...                  0.0   \n",
      "159              0                1               0  ...                  0.0   \n",
      "460              0                0               0  ...                 -1.0   \n",
      "453              0                0               0  ...                 -1.0   \n",
      "..             ...              ...             ...  ...                  ...   \n",
      "351              1                0               0  ...                  0.0   \n",
      "346              1                0               0  ...                  0.0   \n",
      "38               0                0               0  ...                  0.0   \n",
      "667              0                0               0  ...                 -1.0   \n",
      "259              0                0               0  ...                  0.0   \n",
      "\n",
      "     html_malicious_form  html_most_common  html_num_of_css_internal  \\\n",
      "92                   0.0          0.015464                       0.0   \n",
      "148                  0.0          0.052632                       0.0   \n",
      "159                  0.0          0.122137                       0.0   \n",
      "460                 -1.0         -1.000000                      -1.0   \n",
      "453                 -1.0         -1.000000                      -1.0   \n",
      "..                   ...               ...                       ...   \n",
      "351                  0.0          0.044944                       0.0   \n",
      "346                  0.0          0.038462                       0.0   \n",
      "38                   1.0          0.026415                       0.0   \n",
      "667                 -1.0         -1.000000                      -1.0   \n",
      "259                  0.0          0.000000                       0.0   \n",
      "\n",
      "     html_num_of_css_external  html_num_of_anchors_to_content  \\\n",
      "92                        0.0                             0.0   \n",
      "148                       0.0                             0.0   \n",
      "159                       0.0                             0.0   \n",
      "460                      -1.0                            -1.0   \n",
      "453                      -1.0                            -1.0   \n",
      "..                        ...                             ...   \n",
      "351                       0.0                             0.0   \n",
      "346                       0.0                             0.0   \n",
      "38                        0.0                             0.0   \n",
      "667                      -1.0                            -1.0   \n",
      "259                       0.0                             0.0   \n",
      "\n",
      "     html_num_of_anchors_to_void  html_num_of_blank_spaces  \\\n",
      "92                           0.0                       0.0   \n",
      "148                          0.0                     404.0   \n",
      "159                          0.0                     579.0   \n",
      "460                         -1.0                      -1.0   \n",
      "453                         -1.0                      -1.0   \n",
      "..                           ...                       ...   \n",
      "351                          0.0                    3496.0   \n",
      "346                          0.0                    2285.0   \n",
      "38                           0.0                    1048.0   \n",
      "667                         -1.0                      -1.0   \n",
      "259                          0.0                       0.0   \n",
      "\n",
      "     html_blocked_keywords_label     label  \n",
      "92                           0.0    benign  \n",
      "148                          0.0    benign  \n",
      "159                          1.0  phishing  \n",
      "460                         -1.0       dga  \n",
      "453                         -1.0       dga  \n",
      "..                           ...       ...  \n",
      "351                          0.0   malware  \n",
      "346                          1.0   malware  \n",
      "38                           0.0    benign  \n",
      "667                         -1.0       dga  \n",
      "259                          0.0  phishing  \n",
      "\n",
      "[210 rows x 265 columns]\n",
      "===== Processing chunk 1/7 =====\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The input data has 41 features, but the model expects 39 features.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===== Processing chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m =====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m chunk_without_label \u001b[38;5;241m=\u001b[39m chunk_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmapped_label\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_label\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;66;03m# Label should not be known to classifiers\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m chunk_results \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassify_domains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_without_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Collect predictions and true labels\u001b[39;00m\n\u001b[1;32m     62\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m chunk_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/git/domainradar-clf/classifiers/pipeline.py:532\u001b[0m, in \u001b[0;36mPipeline.classify_domains\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    521\u001b[0m stats\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m    522\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m    523\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmalware_residual_result\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m     inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    529\u001b[0m )\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# Calculate the overall badness probability\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbadness_probability\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_badness_probability\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    534\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# DGA Families\u001b[39;00m\n\u001b[1;32m    537\u001b[0m stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdga_families\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf_dga_multiclass_lgbm\u001b[38;5;241m.\u001b[39mclassify(df)\n",
      "File \u001b[0;32m~/git/domainradar-clf/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/git/domainradar-clf/.venv/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/domainradar-clf/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/git/domainradar-clf/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/git/domainradar-clf/classifiers/pipeline.py:164\u001b[0m, in \u001b[0;36mPipeline.calculate_badness_probability\u001b[0;34m(self, domain_stats)\u001b[0m\n\u001b[1;32m    161\u001b[0m working_stats\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmalware_html_lgbm_result\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Make prediction with the decision-making NN\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m badness_probability \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclf_decision_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdomain_stats\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Heuristics\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    170\u001b[0m     domain_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphishing_avg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.75\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m domain_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmalware_avg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.75\u001b[39m\n\u001b[1;32m    171\u001b[0m ):\n",
      "File \u001b[0;32m~/git/domainradar-clf/classifiers/Clf_decision_nn.py:70\u001b[0m, in \u001b[0;36mClf_decision_nn.classify\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Check whether the number of features is correct\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_feature_size:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input data has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but the model expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_feature_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Cast timestamps\u001b[39;00m\n\u001b[1;32m     74\u001b[0m input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcast_timestamp(input_data)\n",
      "\u001b[0;31mValueError\u001b[0m: The input data has 41 features, but the model expects 39 features."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from classifiers.pipeline import Pipeline\n",
    "from classifiers.options import PipelineOptions\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the classification pipeline\n",
    "clf_options = PipelineOptions()\n",
    "print(clf_options)\n",
    "clf = Pipeline(clf_options)\n",
    "print(clf)\n",
    "# Read the input parquet file\n",
    "input_df = pd.read_parquet(test_dataset)\n",
    "print(input_df)\n",
    "# Function to map labels to 'benign' or 'malign'\n",
    "def map_label(label):\n",
    "    if label == 'benign':\n",
    "        return 'benign'\n",
    "    else:\n",
    "        return f'malign ({label})'\n",
    "\n",
    "# Function to convert labels to binary classes\n",
    "def binary_label(label):\n",
    "    return 'negative' if label == 'benign' else 'positive'\n",
    "\n",
    "# Apply label mapping\n",
    "input_df['mapped_label'] = input_df['label'].apply(map_label)\n",
    "input_df['binary_label'] = input_df['label'].apply(binary_label)\n",
    "\n",
    "# Ensure SHAP JavaScript initialization\n",
    "#shap.initjs()\n",
    "\n",
    "# Determine the number of chunks\n",
    "num_chunks = (len(input_df) + CHUNK_SIZE - 1) // CHUNK_SIZE if CHUNK_SIZE > 0 else 1\n",
    "\n",
    "# Initialize counters for overall statistics\n",
    "total_true_labels = []\n",
    "total_pred_labels = []\n",
    "\n",
    "# Format string for aligned output\n",
    "header_format_str = \"{:<3} | {:<50} | {:<18} | {:<10} | {:<10}\"\n",
    "data_format_str = \"{:<3} | {:<50} | {:<18} | {:<10} | {:.6f}\"\n",
    "\n",
    "# Process the dataframe in chunks\n",
    "for i in range(num_chunks):\n",
    "    if CHUNK_SIZE > 0:\n",
    "        start_idx = i * CHUNK_SIZE\n",
    "        end_idx = start_idx + CHUNK_SIZE\n",
    "        chunk_df = input_df[start_idx:end_idx]\n",
    "    else:\n",
    "        chunk_df = input_df\n",
    "\n",
    "    # Perform your classification or processing on the working_df here\n",
    "    print(f\"===== Processing chunk {i+1}/{num_chunks} =====\")\n",
    "\n",
    "    chunk_without_label = chunk_df.drop(columns=['label', 'mapped_label', 'binary_label']) # Label should not be known to classifiers\n",
    "    chunk_results = clf.classify_domains(chunk_without_label)\n",
    "\n",
    "    # Collect predictions and true labels\n",
    "    true_labels = chunk_df['binary_label'].values\n",
    "    pred_labels = []\n",
    "    for result in chunk_results:\n",
    "        pred_label = 'negative' if result['aggregate_probability'] < 0.5 else 'positive'\n",
    "        pred_labels.append(pred_label)\n",
    "\n",
    "    # Update overall statistics\n",
    "    total_true_labels.extend(true_labels)\n",
    "    total_pred_labels.extend(pred_labels)\n",
    "\n",
    "    # Display header for results\n",
    "    print(header_format_str.format(\"Res\", \"Domain Name\", \"Actual Label\", \"Predicted\", \"Probability\"))\n",
    "\n",
    "    # Display results for each domain\n",
    "    for idx, result in enumerate(chunk_results):\n",
    "        actual_label = chunk_df.iloc[idx]['mapped_label']\n",
    "        predicted_label = 'benign' if pred_labels[idx] == 'negative' else 'malign'\n",
    "        domain_name = result['domain_name']\n",
    "        aggregate_probability = result['aggregate_probability']\n",
    "        status = \"OK\" if pred_labels[idx] == true_labels[idx] else \"ER\"\n",
    "        print(data_format_str.format(status, domain_name[:50], actual_label, predicted_label, aggregate_probability))\n",
    "        \n",
    "        # Run debug_domain method for misclassified domains\n",
    "        #if status == \"ER\":\n",
    "            #print(f\"Debugging misclassified domain: {domain_name}\")\n",
    "            #ndf_data = clf.pp.df_to_NDF(chunk_df, \"phishing\")  # Convert to NDF\n",
    "            #debug_data = clf.clf_phishing_cnn.debug_domain(domain_name, ndf_data, chunk_df, n_top_features=10)\n",
    "            \n",
    "            # Print out the top n feature importances and values for each classifier\n",
    "            #for classifier, data in debug_data.items():\n",
    "            #    print(f\"\\nClassifier: {classifier}\")\n",
    "            #    print(f\"Top {len(data['top_features'])} features for domain '{domain_name}':\")\n",
    "            #    for feature_info in data['top_features']:\n",
    "            #        print(f\"Feature: {feature_info['feature']}, Value: {feature_info['value']}, SHAP Value: {feature_info['shap_value']}\")\n",
    "                \n",
    "                # Display the force plot for phishing_lgbm\n",
    "                #if classifier == \"phishing_cnn\":\n",
    "                #    base_value, shap_values, domain_row = data['force_plot_data']\n",
    "                #    shap.force_plot(base_value, shap_values, domain_row)\n",
    "                #    plt.show()\n",
    "\n",
    "    # Calculate metrics for the current chunk\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    precision = precision_score(true_labels, pred_labels, pos_label='positive', average='binary')\n",
    "    recall = recall_score(true_labels, pred_labels, pos_label='positive', average='binary')\n",
    "    f1 = f1_score(true_labels, pred_labels, pos_label='positive', average='binary')\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, pred_labels, labels=['negative', 'positive']).ravel()\n",
    "    false_positives = fp\n",
    "    false_negatives = fn\n",
    "    total_positives = tp + fp\n",
    "    total_negatives = tn + fn\n",
    "\n",
    "    fp_ratio = (false_positives / total_positives) if total_positives > 0 else 0\n",
    "    fn_ratio = (false_negatives / total_negatives) if total_negatives > 0 else 0\n",
    "\n",
    "    print(f\"Chunk {i+1}/{num_chunks} metrics:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"False Positives: {false_positives} ({fp_ratio * 100:.2f}%)\")\n",
    "    print(f\"False Negatives: {false_negatives} ({fn_ratio * 100:.2f}%)\")\n",
    "    print(f\"===== Chunk {i+1}/{num_chunks} completed. =====\")\n",
    "\n",
    "# Calculate overall metrics\n",
    "overall_accuracy = accuracy_score(total_true_labels, total_pred_labels)\n",
    "overall_precision = precision_score(total_true_labels, total_pred_labels, pos_label='positive', average='binary')\n",
    "overall_recall = recall_score(total_true_labels, total_pred_labels, pos_label='positive', average='binary')\n",
    "overall_f1 = f1_score(total_true_labels, total_pred_labels, pos_label='positive', average='binary')\n",
    "\n",
    "overall_tn, overall_fp, overall_fn, overall_tp = confusion_matrix(total_true_labels, total_pred_labels, labels=['negative', 'positive']).ravel()\n",
    "overall_false_positives = overall_fp\n",
    "overall_false_negatives = overall_fn\n",
    "overall_total_positives = overall_tp + overall_fp\n",
    "overall_total_negatives = overall_tn + overall_fn\n",
    "\n",
    "overall_fp_ratio = (overall_false_positives / overall_total_positives) if overall_total_positives > 0 else 0\n",
    "overall_fn_ratio = (overall_false_negatives / overall_total_negatives) if overall_total_negatives > 0 else 0\n",
    "\n",
    "print(\"Overall metrics:\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy}\")\n",
    "print(f\"Overall Precision: {overall_precision}\")\n",
    "print(f\"Overall Recall: {overall_recall}\")\n",
    "print(f\"Overall F1 Score: {overall_f1}\")\n",
    "print(f\"Overall False Positives: {overall_false_positives} ({overall_fp_ratio * 100:.2f}%)\")\n",
    "print(f\"Overall False Negatives: {overall_false_negatives} ({overall_fn_ratio * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ffbfb7-dd7b-4066-b0d7-51249fc2d67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8bb00-5270-45ca-b715-bf73cf72ac7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
